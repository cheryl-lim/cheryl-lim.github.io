{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "## Objective - To predict divorce with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix , classification_report, f1_score,\\\n",
    "                            accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load in the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...  Atr46  \\\n",
       "0     2     2     4     1     0     0     0     0     0      0  ...      2   \n",
       "1     4     4     4     4     4     0     0     4     4      4  ...      2   \n",
       "2     2     2     2     2     1     3     2     1     1      2  ...      3   \n",
       "3     3     2     3     2     3     3     3     3     3      3  ...      2   \n",
       "4     2     2     1     1     1     1     0     0     0      0  ...      2   \n",
       "5     0     0     1     0     0     2     0     0     0      1  ...      2   \n",
       "6     3     3     3     2     1     3     4     3     2      2  ...      3   \n",
       "7     2     1     2     2     2     1     0     3     3      2  ...      0   \n",
       "8     2     2     1     0     0     4     1     3     3      3  ...      1   \n",
       "9     1     1     1     1     1     2     0     2     2      2  ...      2   \n",
       "\n",
       "   Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0      1      3      3      3      2      3      2      1      1  \n",
       "1      2      3      4      4      4      4      2      2      1  \n",
       "2      2      3      1      1      1      2      2      2      1  \n",
       "3      2      3      3      3      3      2      2      2      1  \n",
       "4      1      2      3      2      2      2      1      0      1  \n",
       "5      2      1      2      1      1      1      2      0      1  \n",
       "6      2      3      2      3      3      2      2      2      1  \n",
       "7      1      2      2      2      1      1      1      0      1  \n",
       "8      1      1      1      1      1      1      1      1      1  \n",
       "9      0      2      2      2      2      4      3      3      1  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"divorce.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the data and train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['Atr15','Atr17','Atr19','Atr26','Atr38','Atr40']]\n",
    "y=df['Class']\n",
    "\n",
    "# Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores: [1.         1.         0.95974235 1.         0.96      ]\n",
      "Mean & standard deviation: 0.98 0.02\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation using F1-score as scorer\n",
    "scores = cross_val_score(logreg, \n",
    "                         X_train, \n",
    "                         y_train, \n",
    "                         cv=5, \n",
    "                         scoring='f1_macro')\n",
    "print('F1 scores:', scores)\n",
    "print('Mean & standard deviation: {:.2} {:.2f}'.format(scores.mean(), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection - Train and evaluate multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to keep track of model metrics\n",
    "models = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_score_list = []\n",
    "training_acc_list = []\n",
    "testing_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.74 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(n_jobs=-1), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameter tuning using K-fold cross validation\n",
    "# ... via Grid Search method\n",
    "param_grid = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "              'C': np.logspace(-2, 2, 5)}\n",
    "\n",
    "gs_logreg = GridSearchCV(logreg,\n",
    "                      param_grid, \n",
    "                      cv=5,\n",
    "                      scoring='f1_macro',\n",
    "                      n_jobs=-1)\n",
    "gs_logreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10.0, n_jobs=-1)\n",
      "{'C': 10.0, 'penalty': 'l2'}\n",
      "0.9919484702093397\n"
     ]
    }
   ],
   "source": [
    "# Best model hyperparameters and score\n",
    "print(gs_logreg.best_estimator_)\n",
    "print(gs_logreg.best_params_)\n",
    "print(gs_logreg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, n_jobs=-1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using best estimator found by GridSearchCV\n",
    "logreg = gs_logreg.best_estimator_\n",
    "logreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        22\n",
      "           1       1.00      0.95      0.98        21\n",
      "\n",
      "    accuracy                           0.98        43\n",
      "   macro avg       0.98      0.98      0.98        43\n",
      "weighted avg       0.98      0.98      0.98        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Logistic Regression')\n",
    "precision_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "recall_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "training_acc_list.append(accuracy_score(y_train, logreg.predict(X_train_scaled)))\n",
    "testing_acc_list.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [5, 10, 25],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameter tuning using K-fold cross validation\n",
    "# ... via Grid Search method\n",
    "param_grid = {'n_estimators': [100, 200, 300],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [5, 10, 25],\n",
    "              'min_samples_split': [5, 10, 15]}\n",
    "\n",
    "gs_rf = GridSearchCV(rf,\n",
    "                    param_grid, \n",
    "                    cv=5,\n",
    "                    scoring='f1_macro',\n",
    "                    n_jobs=-1)\n",
    "gs_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=5, min_samples_split=5, random_state=0)\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.9684722797331494\n"
     ]
    }
   ],
   "source": [
    "# Best model hyperparameters and score\n",
    "print(gs_rf.best_estimator_)\n",
    "print(gs_rf.best_params_)\n",
    "print(gs_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_split=5, random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using best estimator found by GridSearchCV\n",
    "rf = gs_rf.best_estimator_\n",
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        22\n",
      "           1       1.00      0.95      0.98        21\n",
      "\n",
      "    accuracy                           0.98        43\n",
      "   macro avg       0.98      0.98      0.98        43\n",
      "weighted avg       0.98      0.98      0.98        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Random Forest')\n",
    "precision_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "recall_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "training_acc_list.append(accuracy_score(y_train, rf.predict(X_train_scaled)))\n",
    "testing_acc_list.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Level Perceptron (stochastic iterative)\n",
    "mlp = MLPClassifier(solver='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(solver='sgd'), n_jobs=-1,\n",
       "             param_grid={'alpha': array([0.0001, 0.001 , 0.01  , 0.1   ]),\n",
       "                         'hidden_layer_sizes': [(3, 3), 2, 3],\n",
       "                         'max_iter': [400, 450, 500, 550]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameter tuning using K-fold cross validation\n",
    "# ... via Grid Search method\n",
    "param_grid = {'hidden_layer_sizes': [(3,3),\n",
    "                                     (2),\n",
    "                                     (3)], \n",
    "              'alpha': np.logspace(-4, -1, 4),\n",
    "              'max_iter': [400, 450, 500, 550]}\n",
    "\n",
    "gs_mlp = GridSearchCV(mlp,\n",
    "                      param_grid, \n",
    "                      cv=5,\n",
    "                      scoring='f1_macro',\n",
    "                      n_jobs=-1)\n",
    "gs_mlp.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(alpha=0.001, hidden_layer_sizes=(3, 3), max_iter=450,\n",
      "              solver='sgd')\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (3, 3), 'max_iter': 450}\n",
      "0.9919484702093397\n"
     ]
    }
   ],
   "source": [
    "# Best model hyperparameters and score\n",
    "print(gs_mlp.best_estimator_)\n",
    "print(gs_mlp.best_params_)\n",
    "print(gs_mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (450) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=(3, 3), max_iter=450,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using best estimator found by GridSearchCV\n",
    "mlp = gs_mlp.best_estimator_\n",
    "mlp.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        22\n",
      "           1       1.00      0.90      0.95        21\n",
      "\n",
      "    accuracy                           0.95        43\n",
      "   macro avg       0.96      0.95      0.95        43\n",
      "weighted avg       0.96      0.95      0.95        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('Multilevel Perceptron')\n",
    "precision_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "recall_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "training_acc_list.append(accuracy_score(y_train, mlp.predict(X_train_scaled)))\n",
    "testing_acc_list.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = pd.DataFrame(zip(models, training_acc_list, testing_acc_list,\n",
    "                                 precision_list, recall_list, f1_score_list), \n",
    "                             columns=['Model', 'Training Acc', 'Testing Acc', 'Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Acc</th>\n",
       "      <th>Testing Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multilevel Perceptron</td>\n",
       "      <td>0.984252</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.953261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Training Acc  Testing Acc  Precision    Recall  \\\n",
       "0    Logistic Regression      1.000000     0.976744   0.978261  0.976190   \n",
       "1          Random Forest      0.992126     0.976744   0.978261  0.976190   \n",
       "2  Multilevel Perceptron      0.984252     0.953488   0.958333  0.952381   \n",
       "\n",
       "   F1 Score  \n",
       "0  0.976694  \n",
       "1  0.976694  \n",
       "2  0.953261  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Predict and Evaluate with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction by selected model\n",
    "y_pred = logreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        22\n",
      "           1       1.00      0.95      0.98        21\n",
      "\n",
      "    accuracy                           0.98        43\n",
      "   macro avg       0.98      0.98      0.98        43\n",
      "weighted avg       0.98      0.98      0.98        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Predicted')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ20lEQVR4nO3deZRcZZmA8ec1CQImEEInEPagKKMiyxFRkFFwAQaQRUQ2RUSQkWH3qCNbAHH0GIgK6BA3YEAEBBQUwYMsCTAkLEISQIwagSGIdBIICYhJ9zt/VAXbkHQXoW7fpL/nd06frrpV1fcNp3ly81XVrchMJEkD3+vqHkCS1D8MviQVwuBLUiEMviQVwuBLUiEG1z3Asmyz4Xt9+ZBWSGdP/G7dI0jLtNuYLWJZt3mEL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVAiDL0mFMPiSVIjBdQ+g9lpn9CjO/OYpdIwcQXd3cs2Pr+PyH17F8Sd/jh0/uAOLFi7kicdmMfakrzJ/3vy6x1XBfnzuBTw8+T6GDl+TL104vu5xiuAR/gDT1dXF+LPO56M7H8Khex3J/ofuy5jNNuHuSfew/wc/ycc//Cke/9MTfProT9Q9qgq33Yd24rNfOaXuMYpi8AeYzr/O5nfTfw/ACwteZOYf/syodTu4e+I9dHV1ATDttw8xavTIOseUeOMWb2X1YUPrHqMolQY/IjaIiGsj4pmIeDoiro6IDarcp/5h9Abr8pa3vZnpv334n7bvtf/u3HXr3TVNJakuVR/h/wi4DhgNrA9c39y2VBFxZETcGxH3ds7/S8WjDWyrrb4a4y48m3PGfosF8194efvhx3ySRV1d3HDtr2ucTlIdqg7+yMz8UWYuan5dBCxzLSEzJ2TmOzPznR1D1614tIFr8OBBjJvwFW742a+55caJL2/fY79d2fED23PKMWfUOJ2kulQd/M6IOCQiBjW/DgFmV7zP4p32jf9k5ozHuOx7V7y8bfv3b8en/v1gjv/0l/jb316qcTpJdYnMrO6HR2wEnA+8B0jgLuC4zHysr8dus+F7qxtsANtq23fww2u+w4xH/kB3d+M/4flfv5AvnHk8Q1YZwnNz5wEw7f6H+OqXx9U56krr7InfrXuEAeHi/xrPH6c+xPx5zzNsrTXZ7ZCP8+5dP1D3WCu93cZsEcu6rdLgvxYGXysqg68VWW/Br+SNVxFxWi83Z2aeVcV+JUnLVtU7bRcsZdsbgMOBtQGDL0n9rJLgZ+Y5iy9HxDDgOOAw4CfAOct6nCSpOpWdSyciRgAnAgcDFwPbZObcqvYnSepdVWv43wD2BSYAW2SmZ+mSpJpV9Tr8k4D1gFOAWRExr/n1fETMq2ifkqReVLWG70nZJGkFY5glqRAGX5IKYfAlqRAGX5IKYfAlqRAGX5IKYfAlqRAGX5IKYfAlqRAGX5IKYfAlqRAGX5IKYfAlqRAGX5IKYfAlqRAGX5IKYfAlqRAGX5IKYfAlqRAGX5IKYfAlqRCDe7sxIkb0dntmzmnvOJKkqvQafOA+IIEANgLmNi8PBx4HxlQ5nCSpfXpd0snMMZm5KXATsGdmdmTm2sAewDX9MaAkqT1aXcPfNjNvWHwlM38FvK+akSRJVehrSWexzog4BbiUxhLPIcDsyqaSJLVdq0f4BwIjgWubXyOb2yRJK4mWjvCbr8Y5LiKGZub8imeSJFWgpSP8iNg+Ih4GHm5e3zIivlPpZJKktmp1SWc8sAvNdfvMfBD416qGkiS1X8vvtM3MJ5bY1NXmWSRJFWr1VTpPRMT2QEbEKsCxwCPVjSVJardWj/CPAo4G1gf+D9gK+FxFM0mSKtDqEf5bMvPgnhsiYgfgzvaPJEmqQqtH+Oe1uE2StILq62yZ7wG2B0ZGxIk9bloDGFTlYJKk9uprSWcVYGjzfsN6bJ8H7FfVUJKk9us1+Jl5O3B7RFyUmY/100ySpAq0uob//YgYvvhKRKwVETdVM5IkqQqtBr8jM59dfCUz5wKjKplIklSJVoPfHREbLb4SERvTOE2yJGkl0err8E8G7oiI25vX/xU4spqRJElViMzWDtQjogN4N43PtP3fzOyscrBJsx71XxBaIZ26y6l1jyAt023Troxl3dbrkk5EbN78vg2NDzGfBTwJbNTcJklaSfS1pHMScARwzlJuS2Dntk8kSapEX6/DP6L5faf+GUeSVJW+Tq2wb2+3Z+Y17R1HklSVvpZ09mx+H0XjnDq3NK/vBNwGGHxJWkn0taRzGEBE/AJ4a2Y+1bw+Grig+vEkSe3S6huvNlkc+6angTdXMI8kqSKtvvHqtua5cy6n8eqcA4BbK5tKktR2LQU/M/8jIvah8Q5bgAmZeW11Y0mS2q3VI3yA+4HnM/PmiFg9IoZl5vNVDSZJaq+W1vAj4gjgp8CFzU3rAz+raCZJUgVafdL2aGAHGp90RWbOwNMjS9JKpdXgv5SZf198JSIG4+mRJWml0mrwb4+ILwOrRcSHgKuA66sbS5LUbq0G/4vAM8A04LPADcApVQ0lSWq/Pl+lExGvA6Zm5tuB71U/kiSpCn0e4WdmN/Bgz484lCStfFp9Hf5o4KGImAIsWLwxMz9SyVSSpLZrNfhnVDqFJKlyfZ0Pf1XgKOBNNJ6w/UFmLuqPwSRJ7dXXGv7FwDtpxH43lv5Rh5KklUBfSzpvzcwtACLiB8CU6keSJFWhryP8hYsvuJQjSSu3vo7wt4yIec3LQeOdtvOalzMz16h0OklS2/T1EYeD+msQSVK1Wj21giRpJWfwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQBl+SCmHwJakQg+seQNWaPuU+Lj//+3R3dbHj7h/m3w7ar+6RVLCR66zNl796NCM6htPdnfzipzdz9WW/Ytgab+D0cSew7noj+cusZxj7+fHMn7eg7nEHHI/wB7Duri4u+9aFHP+10znroguY8puJzPrz43WPpYJ1dXXxnXH/w6F7ncjnDj6ZvQ/YhY03XZ+DDt+b+ydP45A9juP+ydM46PC96x51QKos+BHxxoh4ffPy+yPi2IgYXtX+9EozfzeDUeuNZuR66zJ4yBDetfOOPHDn5LrHUsHmdD7LjEdmAvDiC3/jsZlP0rHOCHbYaVtu/PntANz489t5707b1jnmgFXlEf7VQFdEvAn4ATAG+HGF+9MS5nbOZq1RHS9fX2tkB3M7Z9c4kfQP6643ks02H8MjU//AiLXXZE7ns0DjL4W11l6j3uEGqCqD352Zi4B9gG9m5gnA6N4eEBFHRsS9EXHvdZdeUeFohch8xaaIqGEQ6Z+tttrrOWP8SZz/9Yt4YcGLdY9TjCqftF0YEQcChwJ7NrcN6e0BmTkBmAAwadajr6yVXpW1RnYw96+dL1+f+0wnw9ceUeNEEgwaPIgzxp/Ezb+cxKTfTAFgzuznGNExnDmdzzKiYzhzZ8+recqBqcoj/MOA9wBnZ+bMiBgDXFrh/rSETTbfjKefnMUzT/2FRQsXMuWWSWy5/XZ1j6XCfeGMo3j8T09y1SW/fHnbXbfdy657vQ+AXfd6H3feek9d4w1okUv5Z3/bfnjEasBGmfnoq32sR/jtMfXue7nigu/T3d3NDrt9kD0O2b/ukVZ6p+5yat0jrLS22PotnHfJWfzx94+R3Y3/xb/37ct5ZOoMTh93AuuM7uDppzoZe9K5PO/LMpfLbdOuXOa6bWXBj4g9gXHAKpk5JiK2As7MzI+08niDrxWVwdeKrLfgV7mkMxZ4F/AsQGY+QOOVOpKkGlQZ/EWZ+dwS2zxql6SatD34EXFD8wna6RFxEDAoIjaLiPOAu9q9P0lSa6o4wr8IuAn4M/B24CUab7h6Djiugv1JklrQ9uBn5pXA1sBQYHfgCuAnwFzg6HbvT5LUmqreeLUQWAC8nkb4XbuXpJq1PfgRsStwLnAdsE1mvtDufUiSXr0qjvBPBj6WmQ9V8LMlScup7cHPzB3b/TMlSa+dH4AiSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYUw+JJUCIMvSYWIzKx7BvWDiDgyMyfUPYe0JH83+49H+OU4su4BpGXwd7OfGHxJKoTBl6RCGPxyuEaqFZW/m/3EJ20lqRAe4UtSIQy+JBXC4A8wEZERcU6P65+PiLE1jqTCRcMdEbFbj237R8SNdc5VIoM/8LwE7BsRHXUPIgFk44nCo4BzI2LViHgDcDZwdL2TlcfgDzyLaLzq4YQlb4iIjSPiNxExtfl9o/4fTyXKzOnA9cAXgdOBS4GTI+KeiPhtROwFEBFvi4gpEfFA8/d0sxrHHnB8lc4AExHzgfWAqcCWwBHA0MwcGxHXAz/NzIsj4tPARzJz7/qmVUmaR/b3A38HfgE8lJmXRsRwYAqwNfA14O7MvCwiVgEGZeaLdc080Bj8ASYi5mfm0Ig4E1gIvMg/gt8JjM7MhRExBHgqM136Ub9p/l7OB/YHVqXxL1KAEcAuNKJ/MnAJcE1mzqhjzoFqcN0DqDLfpHE09aNe7uPf9upv3c2vAD6amY8ucfsjETEZ2B24KSI+k5m39PeQA5Vr+ANUZs4BrgQO77H5LuCA5uWDgTv6ey6p6SbgmIgIgIjYuvl9U+BPmflt4DrgHfWNOPAY/IHtHKDnks2xwGERMRX4BHBcLVNJcBYwBJgaEdOb1wE+DkyPiAeAzWks7ahNXMOXpEJ4hC9JhTD4klQIgy9JhTD4klQIgy9JhTD4Kk5E7NM8q+jmfdzv+IhY/TXs51MRcf7yPl5qN4OvEh1I401nB/Rxv+OB5Q6+tKIx+CpKRAwFdqDxDuQDmtsGRcS4iJjWPEPjMRFxLI2T0N0aEbc27ze/x8/ZLyIual7eMyImN8/6eHNErLOU/X4sIqZHxIMRMbH6P6n0Sp5LR6XZG7gxM38fEXMiYhtgO2AMsHVmLoqIEZk5JyJOBHbKzM4+fuYdwLszMyPiM8AXgJOWuM9pwC6Z+WTz7JBSvzP4Ks2BNE4sB/CT5vVNgf/OzEXw8nmIXo0NgCsiYjSwCjBzKfe5E7goIq4ErlmOuaXXzOCrGBGxNrAz8PaISGAQjTOG3kdrZw7teZ9Ve1w+Dzg3M6+LiPcDY1/xwMyjImI7GmeBfCAitsrM2cvz55CWl2v4Ksl+wCWZuXFmbpKZG9I4Gr8fOCoiBgNExIjm/Z8HhvV4/NMR8S8R8Tpgnx7b1wSebF4+dGk7jog3ZubkzDwN6AQ2bNufSmqRwVdJDgSuXWLb1TSenH2cxpkbHwQOat42AfjV4idtgS/R+KSmW4CnevyMscBVETGJRsyX5hvNJ4WnAxOBB1/jn0V61TxbpiQVwiN8SSqEwZekQhh8SSqEwZekQhh8SSqEwZekQhh8SSrE/wNjtgVqpKAK/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_mat.T, annot=True, fmt='d', cbar=False, cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True),\n",
    "          xticklabels=['No','Yes'],\n",
    "          yticklabels=['No','Yes'] )\n",
    "plt.xlabel('Actuals')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
